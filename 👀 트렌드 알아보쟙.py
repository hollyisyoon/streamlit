import pandas as pd
import koreanize_matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from matplotlib.colors import to_rgba
import plotly.graph_objects as go
import plotly.express as px
import ast
import time

import streamlit as st
from streamlit_extras.let_it_rain import rain

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from collections import Counter
from wordcloud import WordCloud
from datetime import datetime, timedelta

import warnings
warnings.filterwarnings("ignore", message="PyplotGlobalUseWarning")
import networkx as nx
from gensim.models import Word2Vec
import time

rain(emoji="ğŸ¦",
    font_size=54,
    falling_speed=10,
    animation_length="infinite")

#ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('/app/busypeople-stramlit/data/plant_gallery.csv', encoding='utf8')
df['time'] = pd.to_datetime(df['time'])
def to_list(text):
    return ast.literal_eval(text)

def get_tfidf_top_words(df, start_date, last_date, num_words, media):
    df = df[df['name'] == media]
    df = df[(df['time'] >= start_date) & (df['time'] <= last_date)]
    tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords)
    tfidf = tfidf_vectorizer.fit_transform(df['title+content'].values)
    tfidf_df = pd.DataFrame(tfidf.todense(), columns=tfidf_vectorizer.get_feature_names_out())
    tfidf_top_words = tfidf_df.sum().sort_values(ascending=False).head(num_words).to_dict()
    tfidf_top_words = dict(tfidf_top_words)
    return tfidf_top_words

def get_count_top_words(df, start_date, last_date, num_words, media):
    df = df[df['name'] == media]
    df = df[(df['time'] >= start_date) & (df['time'] <= last_date)]
    count_vectorizer = CountVectorizer(stop_words=stopwords)
    count = count_vectorizer.fit_transform(df['title+content'].values)
    count_df = pd.DataFrame(count.todense(), columns=count_vectorizer.get_feature_names_out())
    count_top_words = count_df.sum().sort_values(ascending=False).head(num_words).to_dict()
    return count_top_words

def keyword_timeseries(df, start_date, last_date, media, keyword):
    df['title+content'] = df['title+content'].astype(str)
    df = df[(df['title+content'].str.contains(keyword)) & (df['name'] == media)]
    mask = (df['time'] >= start_date) & (df['time'] <= last_date)
    df = df.loc[mask]
    df_daily_views = df.groupby(df['time'].dt.date)['view'].sum().reset_index()
    return df_daily_views

def get_words(df, col, keyword):
    df[col] = df[col].map(to_list)
    text_list=[]
    for sublist in df[col]:
        text_list.append(sublist)
    model = Word2Vec(text_list, vector_size=100, window=5, min_count=1, workers=3, epochs=30)
    try:
        similar_words = model.wv.most_similar(keyword, topn=10)
        results = [(keyword, word, score) for word, score in similar_words]
        return results
    except:
        return None

def show_modal(df):
    st.table(df) 

#### ëŒ€ì‹œë³´ë“œ ì‹œì‘ #####
st.title('ì™¸ë¶€ íŠ¸ë Œë“œ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ')

#### ì¸í’‹ í•„í„° #####
col1, col2, col3 = st.beta_columns(3)
with col1:
    start_date = st.date_input("ì‹œì‘ ë‚ ì§œ",
                           value=datetime.today() - timedelta(days=45),
                           min_value=datetime(2022, 4, 27),
                           max_value=datetime(2023, 4, 26))
with col2:
    end_date = st.date_input("ë ë‚ ì§œ", 
                         value=datetime.today() - timedelta(days=30),    
                         min_value=datetime(2022, 4, 27),
                         max_value=datetime(2023, 4, 26))
with col3:
    keyword_no = st.number_input("ğŸ“Œ í‚¤ì›Œë“œ", value=50, min_value=1, step=1)

col1, col2, col3 = st.beta_columns(3)    
with col1:
    type = st.selectbox('ê¸°ì¤€',('ìƒëŒ€ ë¹ˆë„(TF-IDF)','ë‹¨ìˆœ ë¹ˆë„(Countvertize)'))
with col2:
    media = st.selectbox('ë§¤ì²´',('ì‹ë¬¼ê°¤ëŸ¬ë¦¬', 'ë„¤ì´ë²„ì¹´í˜'))
with col3:
    input_str = st.text_input('ì œê±°í•  í‚¤ì›Œë“œ')
    stopwords = [x.strip() for x in input_str.split(',')]

# íƒ€ì… ì˜µì…˜
start_date = pd.Timestamp(start_date)
end_date = pd.Timestamp(end_date)
if type == 'ë‹¨ìˆœ ë¹ˆë„(Countvertize)' :
    words = get_count_top_words(df, start_date, end_date, keyword_no, media)
else :
    words = get_tfidf_top_words(df, start_date, end_date, keyword_no, media)

#ì›Œë“œí´ë¼ìš°ë“œ
wc = WordCloud(background_color="white", colormap='Spectral', contour_color='steelblue', font_path="/app/busypeople-stramlit/font/NanumBarunGothic.ttf")
wc.generate_from_frequencies(words)

###########ë™ì  ì›Œë“œ í´ë¼ìš°ë“œ####################
# ì»¬ëŸ¬ íŒ”ë ˆíŠ¸ ìƒì„±
word_list=[]
freq_list=[]
fontsize_list=[]
position_list=[]
orientation_list=[]
color_list=[]

for (word, freq), fontsize, position, orientation, color in wc.layout_:
    word_list.append(word)
    freq_list.append(freq)
    fontsize_list.append(fontsize)
    position_list.append(position)
    orientation_list.append(orientation)
    color_list.append(color)

# get the positions
x=[]
y=[]
for i in position_list:
    x.append(i[0])
    y.append(i[1])

# WordCloud ì‹œê°í™”ë¥¼ ìœ„í•œ Scatter Plot ìƒì„±
fig = go.Figure(go.Scatter(
    x=x, y=y, mode="text",
    text=word_list,
    textfont=dict(size=fontsize_list, color=color_list),
))
fig.update_layout(title="WordCloud", xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                  yaxis=dict(showgrid=False, zeroline=False, showticklabels=False), hovermode='closest')
st.plotly_chart(fig, use_container_width=True)

###### ë°”ê·¸ë˜í”„ #####
words_count = Counter(words)
words_df = pd.DataFrame([words_count]).T
st.bar_chart(words_df)


#######ì„¸ë¶€ í‚¤ì›Œë“œ########
### ì‹œê³„ì—´ ê·¸ë˜í”„ ###
st.title('ê´€ë ¨ í‚¤ì›Œë“œ ì•Œì•„ë³´ì„¸ìš”!')

search_word = st.text_input('ğŸ”® ë¬´ìŠ¨ í‚¤ì›Œë“œê°€ ê¶ê¸ˆí•˜ì‹ ê°€ìš”', value='ì œë¼ëŠ„')
df_daily_views = keyword_timeseries(df, start_date, end_date, media, search_word)
fig = px.line(df_daily_views, x='time', y='view')
st.plotly_chart(fig, use_container_width=True)

#### ì—°ê´€ê²€ìƒ‰ì–´ #####
if st.button('ë¶„ì„ì„ ì‹œì‘í•˜ê¸°'):
    with st.spinner('ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):
        # Define the data
        data = get_words(df,'title+content', search_word)
        if data is None:
            st.warning('ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. ì¶”ì²œ í‚¤ì›Œë“œ : ì œë¼ëŠ„ğŸŒ¸')
        else:
            df_data = pd.DataFrame(data, columns=["í‚¤ì›Œë“œ", "ì—°ê´€ í‚¤ì›Œë“œ", "ìœ ì‚¬ë„"])

        # Create the network graph
        G = nx.DiGraph()
        for row in data:
            G.add_edge(row[0], row[1], weight=row[2])

        pos = nx.spring_layout(G)

        labels = {}
        for edge in G.edges(data=True):
            labels[(edge[0], edge[1])] = f"{edge[2]['weight']:.2f}"

        edge_widths = [data[i][2] for i in range(len(data))]

        nx.draw_networkx_edges(G, pos)
        nx.draw_networkx_nodes(G, pos, node_color='lightblue', node_size=500)
        nx.draw_networkx_labels(G, pos, font_size=12, font_family='NanumGothic', font_weight='bold')
        nx.draw_networkx_edge_labels(G, pos, edge_labels=labels, font_size=12, font_family='NanumBarunGothic')

        st.success(f"<{search_word}>ì— ëŒ€í•œ ì—°ê´€ì–´ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤ğŸ˜€")
        plt.axis('off')
        st.pyplot()

        expander = st.expander('ë¶„ì„ ê²°ê³¼ ë°ì´í„° ë³´ê¸°')
        with expander:
            show_modal(df_data)

