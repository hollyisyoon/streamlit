import streamlit as st
from gensim.models import Word2Vec
import networkx as nx
from pyvis.network import Network
import gensim
from wordcloud import WordCloud
from datetime import datetime, timedelta
import pandas as pd
from streamlit_tags import st_tags

df = pd.read_csv('/app/streamlit/data/df_á„á…³á„…á…¦á†«á„ƒá…³_github.csv')

st.title('ğŸ” í‚¤ì›Œë“œ DeepDive')
col1, col2 = st.beta_columns((0.2, 0.8))
keyword1 = st.text_input('ê¶ê¸ˆí•œ í‚¤ì›Œë“œ', value='ì œë¼ëŠ„')
keyword2 = st_tags(
    label = 'ë¹„êµí•  í‚¤ì›Œë“œ',
    text = 'ì§ì ‘ ì…ë ¥í•´ë³´ì„¸ìš”(ìµœëŒ€ 5ê°œ)',
    value = ['ì‹ë¬¼ì˜ì–‘ì œ', 'ë¿Œë¦¬ì˜ì–‘ì œ'],
    maxtags = 5,
    key = '2')

keyword_all = [keyword1]+keyword2
network_keywords = [keyword.split() for keyword in df['ì œëª©+ë‚´ìš©(nng)']]

def ë„¤íŠ¸ì›Œí¬(network_keywords):
    networks = []
    for keyword in network_keywords:
        network_keyword = [w for w in keyword if len(w) > 1]
        networks.append(network_keyword)

    model = Word2Vec(networks, vector_size=100, window=5, min_count=1, workers=3, epochs=50)

    G = nx.Graph(font_path='/app/streamlit/font/Pretendard-Bold.otf')

    # ì¤‘ì‹¬ ë…¸ë“œë“¤ì„ ë…¸ë“œë¡œ ì¶”ê°€
    for keyword in keyword_all:
        G.add_node(keyword)
        # ì£¼ì–´ì§„ í‚¤ì›Œë“œì™€ ê°€ì¥ ìœ ì‚¬í•œ 20ê°œì˜ ë‹¨ì–´ ì¶”ì¶œ
        similar_words = model.wv.most_similar(keyword, topn=10)
        # ìœ ì‚¬í•œ ë‹¨ì–´ë“¤ì„ ë…¸ë“œë¡œ ì¶”ê°€í•˜ê³ , ì£¼ì–´ì§„ í‚¤ì›Œë“œì™€ì˜ ì—°ê²°ì„  ì¶”ê°€
        for word, score in similar_words:
            G.add_node(word)
            G.add_edge(keyword, word, weight=score)
            
    # ë…¸ë“œ í¬ê¸° ê²°ì •
    size_dict = nx.degree_centrality(G)

    # ë…¸ë“œ í¬ê¸° ì„¤ì •
    node_size = []
    for node in G.nodes():
        if node in keyword_all:
            node_size.append(5000)
        else:
            node_size.append(1000)

    # í´ëŸ¬ìŠ¤í„°ë§
    clusters = list(nx.algorithms.community.greedy_modularity_communities(G))
    cluster_labels = {}
    for i, cluster in enumerate(clusters):
        for node in cluster:
            cluster_labels[node] = i
            
    # ë…¸ë“œ ìƒ‰ìƒ ê²°ì •
    color_palette = ["#f39c9c", "#f7b977", "#fff4c4", "#d8f4b9", "#9ed6b5", "#9ce8f4", "#a1a4f4", "#e4b8f9", "#f4a2e6", "#c2c2c2"]
    node_colors = [color_palette[cluster_labels[node] % len(color_palette)] for node in G.nodes()]

    # ë…¸ë“œì— ë¼ë²¨ê³¼ ì—°ê²° ê°•ë„ ê°’ ì¶”ê°€
    edge_weights = [d['weight'] for u, v, d in G.edges(data=True)]

    # ì„ ì˜ ê¸¸ì´ë¥¼ ë³€ê²½ pos
    # plt.figure(figsize=(15,15))
    pos = nx.spring_layout(G, seed=42, k=0.15)
    nx.draw(G, pos, font_path='/app/streamlit/font/Pretendard-Bold.otf', with_labels=True, node_size=node_size, node_color=node_colors, alpha=0.8, linewidths=1,
            font_size=9, font_color="black", font_weight="medium", edge_color="grey", width=edge_weights)


    # ì¤‘ì‹¬ ë…¸ë“œë“¤ë¼ë¦¬ ê²¹ì¹˜ëŠ” ë‹¨ì–´ ì¶œë ¥
    overlapping_í‚¤ì›Œë“œ = set()
    for i, keyword1 in enumerate(í‚¤ì›Œë“œ):
        for j, keyword2 in enumerate(í‚¤ì›Œë“œ):
            if i < j and keyword1 in G and keyword2 in G:
                if nx.has_path(G, keyword1, keyword2):
                    overlapping_í‚¤ì›Œë“œ.add(keyword1)
                    overlapping_í‚¤ì›Œë“œ.add(keyword2)
    if overlapping_í‚¤ì›Œë“œ:
        print(f"ë‹¤ìŒ ì¤‘ì‹¬ í‚¤ì›Œë“œë“¤ë¼ë¦¬ ì—°ê´€ì„±ì´ ìˆì–´ ì¤‘ë³µë  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤: {', '.join(overlapping_í‚¤ì›Œë“œ)}")


    net = Network(notebook=True, cdn_resources='in_line')
    net.from_nx(G)
    return [net, similar_words]

network_result = ë„¤íŠ¸ì›Œí¬(network_keywords)

try:
    net = network_result[0]
    net.save_graph(f'/app/streamlit/pyvis_graph.html')
    HtmlFile = open(f'/app/streamlit/pyvis_graph.html', 'r', encoding='utf-8')
    components.html(HtmlFile.read())
except:
    st.write('ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í‚¤ì›Œë“œì˜ˆìš”.')