import streamlit as st
import streamlit.components.v1 as components
from streamlit_tags import st_tags

import plotly.express as px
import plotly.graph_objects as go

# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
import ast
from datetime import datetime
from datetime import timedelta

import warnings
warnings.filterwarnings("ignore", message="PyplotGlobalUseWarning")

from collections import Counter
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import koreanize_matplotlib

from PIL import Image

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

from gensim.models import Word2Vec
import networkx as nx
import gensim
from pyvis.network import Network
from wordcloud import WordCloud

df = pd.read_csv('/app/streamlit/data/df_á„á…³á„…á…¦á†«á„ƒá…³_github.csv')

st.title('ğŸ” í‚¤ì›Œë“œ DeepDive')
col1, col2 = st.beta_columns((0.2, 0.8))
keyword1 = st.text_input('ê¶ê¸ˆí•œ í‚¤ì›Œë“œ', value='ì œë¼ëŠ„')
keyword2 = st_tags(
    label = 'ë¹„êµí•  í‚¤ì›Œë“œ',
    text = 'ì§ì ‘ ì…ë ¥í•´ë³´ì„¸ìš”(ìµœëŒ€ 5ê°œ)',
    value = ['ìŠ¤í‚¨ë‹µì„œìŠ¤'],
    maxtags = 5,
    key = '2')

expander = st.expander('ì—°ê´€ë¶„ì„ ì„¸ë¶€í•„í„°')
with expander:
    media = st.selectbox('ë§¤ì²´',('ì‹ë¬¼ê°¤ëŸ¬ë¦¬', 'ì‹ë¬¼ë³‘ì›', 'ë„¤ì´ë²„ì¹´í˜', 'ë„¤ì´ë²„ë¸”ë¡œê·¸', 'ë„¤ì´ë²„í¬ìŠ¤íŠ¸'), help="í™•ì¸í•˜ê³  ì‹¶ì€ ì™¸ë¶€ ë°ì´í„°ì˜ ë§¤ì²´ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

def extract_df(df, media):
    standard_df = df[(df['ë§¤ì²´'] == media)]
    return standard_df

all_keywords = [keyword1]+keyword2
df2 = extract_df(df, media)
network_list = [eval(i) for i in df2['ì œëª©+ë‚´ìš©(nng)']]

def ë„¤íŠ¸ì›Œí¬(network_list, all_keywords):
    networks = []
    for review in network_list:
        network_review = [w for w in review if len(w) > 1]
        networks.append(network_review)

    model = Word2Vec(networks, vector_size=100, window=5, min_count=1, workers=4, epochs=50)

    G = nx.Graph(font_path='/app/streamlit/font/Pretendard-Bold.otf')

    # ì¤‘ì‹¬ ë…¸ë“œë“¤ì„ ë…¸ë“œë¡œ ì¶”ê°€
    for keyword in all_keywords:
        G.add_node(keyword)
        # ì£¼ì–´ì§„ í‚¤ì›Œë“œì™€ ê°€ì¥ ìœ ì‚¬í•œ 20ê°œì˜ ë‹¨ì–´ ì¶”ì¶œ
        similar_words = model.wv.most_similar(keyword, topn=15)
        # ìœ ì‚¬í•œ ë‹¨ì–´ë“¤ì„ ë…¸ë“œë¡œ ì¶”ê°€í•˜ê³ , ì£¼ì–´ì§„ í‚¤ì›Œë“œì™€ì˜ ì—°ê²°ì„  ì¶”ê°€
        for word, score in similar_words:
            G.add_node(word)
            G.add_edge(keyword, word, weight=score)
            
    # ë…¸ë“œ í¬ê¸° ê²°ì •
    size_dict = nx.degree_centrality(G)

    # ë…¸ë“œ í¬ê¸° ì„¤ì •
    node_size = []
    for node in G.nodes():
        if node in all_keywords:
            node_size.append(5000)
        else:
            node_size.append(1000)

    # í´ëŸ¬ìŠ¤í„°ë§
    clusters = list(nx.algorithms.community.greedy_modularity_communities(G))
    cluster_labels = {}
    for i, cluster in enumerate(clusters):
        for node in cluster:
            cluster_labels[node] = i
            
    # ë…¸ë“œ ìƒ‰ìƒ ê²°ì •
    color_palette = ["#f39c9c", "#f7b977", "#fff4c4", "#d8f4b9", "#9ed6b5", "#9ce8f4", "#a1a4f4", "#e4b8f9", "#f4a2e6", "#c2c2c2"]
    node_colors = [color_palette[cluster_labels[node] % len(color_palette)] for node in G.nodes()]

    # ë…¸ë“œì— ë¼ë²¨ê³¼ ì—°ê²° ê°•ë„ ê°’ ì¶”ê°€
    edge_weights = [d['weight'] for u, v, d in G.edges(data=True)]

    # ì„ ì˜ ê¸¸ì´ë¥¼ ë³€ê²½ pos
    pos = nx.spring_layout(G, seed=42, k=0.15)
    nx.draw(G, pos, with_labels=True, node_size=node_size, node_color=node_colors, alpha=0.8, linewidths=1,
            font_size=9, font_color="black", edge_color="grey", width=edge_weights)

    net = Network(notebook=True, cdn_resources='in_line')
    net.from_nx(G)
    return [net, similar_words]

ë„¤íŠ¸ì›Œí¬ = ë„¤íŠ¸ì›Œí¬(network_list, all_keywords)
if st.button('ë¶„ì„ì„ ì‹œì‘í•˜ê¸°'):
    with st.spinner('ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):
        try:
            net = ë„¤íŠ¸ì›Œí¬[0]
            net.save_graph(f'/app/streamlit/pyvis_graph.html')
            HtmlFile = open(f'/app/streamlit/pyvis_graph.html', 'r', encoding='utf-8')
            components.html(HtmlFile.read(), height=600)
        except:
            st.warning('ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í‚¤ì›Œë“œì˜ˆìš”.')