import koreanize_matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from matplotlib.colors import to_rgba
import plotly.graph_objects as go
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import networkx as nx
from gensim.models import Word2Vec

import pandas as pd
import ast
import time
from datetime import datetime, timedelta
import itertools
from markdownlit import mdlit

#ìŠ¤íŠ¸ë¦¼ì‡
import streamlit as st
from streamlit_extras.let_it_rain import rain
from streamlit_tags import st_tags
import warnings
warnings.filterwarnings("ignore", message="PyplotGlobalUseWarning")

#ê³„ì‚°
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from collections import Counter
from wordcloud import WordCloud



# CSS ìŠ¤íƒ€ì¼ ì •ì˜
css_code = """
<style>
    .custom-sidebar {
        padding: 20px;
        background-color: #f2f2f2;
        font-size: 18px;
        color: #333;
    }
    
    .custom-sidebar a {
        color: #333;
        text-decoration: none;
    }
</style>
"""

############## ì‚¬ì´ë“œë°”
st.sidebar.markdown(f"<style>{css_code}</style>", unsafe_allow_html=True)
st.sidebar.markdown("""
    <div class="custom-sidebar">
        <h2><a href="#section1">ğŸª„í‚¤ì›ŒíŠ¸ ë°œêµ´</a></h2>
        <h2><a href="#section2">ì„œë¸Œíƒ€ì´í‹€ 2</a></h2>
        <h2><a href="#section3">ì„œë¸Œíƒ€ì´í‹€ 3</a></h2>
        <h2><a href="#section4">ì„œë¸Œíƒ€ì´í‹€ 4</a></h2>
    </div>
""", unsafe_allow_html=True)

##############ë©”ì¸ ì½˜í…ì¸ 
st.title("ì™¸ë¶€ íŠ¸ë Œë“œ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ")

#########Section1 - wordcloud############
st.markdown("<h2 id='section1'>ğŸª„í‚¤ì›ŒíŠ¸ ë°œêµ´</h2>", unsafe_allow_html=True)

##ë°ì´í„°##
def to_list(text):
    return ast.literal_eval(text)

df = pd.read_csv('/app/streamlit/data/df_á„á…³á„…á…¦á†«á„ƒá…³_github.csv')
df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'])
def extract_df(df, media, start_date, end_date, effect_size):
    start_date = pd.Timestamp(start_date)
    end_date = pd.Timestamp(end_date)
    standard_df = df[(df['ë§¤ì²´'] == media) & (df['ë‚ ì§œ'] >= start_date) & (df['ë‚ ì§œ'] <= end_date) & (df['ì˜í–¥ë„'] >= effect_size)]
    range_days = (end_date - start_date) + timedelta(days = 1)
    new_day = start_date - range_days
    new_day = pd.Timestamp(new_day)
    new_df = df[(df['ë§¤ì²´'] == media) & (df['ë‚ ì§œ'] >= new_day) & (df['ë‚ ì§œ'] < start_date) & (df['ì˜í–¥ë„'] >= effect_size)]    
    return standard_df, new_df

##ì¸í’‹ í•„í„° - ì „ì²´ìš©##
col1, col2, col3 = st.beta_columns(3)
min_date = datetime(2022, 6, 1)
max_date = datetime(2023, 4, 26)
with col1:
    start_date = st.date_input("ì‹œì‘ ë‚ ì§œ",
                               value=datetime(2022,6,1),
                               min_value=min_date,
                               max_value=max_date - timedelta(days=7))
    # ë ë‚ ì§œë¥¼ ì„ íƒí•  ë•Œ ìµœì†Œ ë‚ ì§œëŠ” ì‹œì‘ ë‚ ì§œì´ë©°, ìµœëŒ€ ë‚ ì§œëŠ” 90ì¼ ì´ì „ê¹Œì§€ë¡œ ì œí•œ
    end_date = st.date_input("ë ë‚ ì§œ",
                             value=datetime(2022,6,15),
                             min_value=start_date + timedelta(days=7),
                             max_value=start_date + timedelta(days=60))
with col2:
    media = st.selectbox('ë§¤ì²´',('ì‹ë¬¼ê°¤ëŸ¬ë¦¬', 'ì‹ë¬¼ë³‘ì›', 'ë„¤ì´ë²„ì¹´í˜', 'ë„¤ì´ë²„ë¸”ë¡œê·¸', 'ë„¤ì´ë²„í¬ìŠ¤íŠ¸'), help="í™•ì¸í•˜ê³  ì‹¶ì€ ì™¸ë¶€ ë°ì´í„°ì˜ ë§¤ì²´ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
with col3:
    temp_effect_size = st.slider('ì˜í–¥ë„ ë³¼ë¥¨', 0, 100, 83, help="ì˜í–¥ë„ ë³¼ë¥¨ì´ë€ ê° ë§¤ì²´ë³„ ì½˜í…ì¸ ì˜ ë°˜ì‘ë„ë¥¼ ì ìˆ˜í™”í•œ ê°’ì…ë‹ˆë‹¤. 0ì— ê°€ê¹Œìš¸ ìˆ˜ë¡ ì˜í–¥ë„ê°€ ë†’ìŠµë‹ˆë‹¤.")
    effect_size = (100-int(temp_effect_size))/100
standard_df, new_df = extract_df(df, media, start_date, end_date, effect_size)

##ì¸í’‹ í•„í„° - ì›Œë“œí´ë¼ìš°ë“œìš©##
expander = st.expander('ì›Œë“œ í´ë¼ìš°ë“œ ì„¸ë¶€í•„í„°')
with expander:
    col1, col2= st.beta_columns(2)    
    with col1:
        type = st.selectbox('ê¸°ì¤€',('ë‹¨ìˆœ ë¹ˆë„(Countvectorizer)','ìƒëŒ€ ë¹ˆë„(TF-IDF)'), help="ë‹¨ìˆœë¹ˆë„ë€ ë¬¸ì„œ ë‚´ ê° ë‹¨ì–´ê°€ ë‚˜íƒ€ë‚œ ë¹ˆë„ ì¦‰, ë‚˜íƒ€ë‚œ íšŸìˆ˜ë¥¼ ì„¸ì„œ ë§Œë“  ê°’ì…ë‹ˆë‹¤. ìƒëŒ€ë¹ˆë„ëŠ” ë‹¨ì–´ê°€ ë¬¸ì„œ ë‚´ì—ì„œ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œì…ë‹ˆë‹¤.")
    with col2:
        keyword_no = st.number_input("í‚¤ì›Œë“œ ë³¼ë¥¨", value=100, min_value=1, step=1)   
    stopwords = st_tags(
        label = 'ì œê±°í•  í‚¤ì›Œë“œ',
        text = 'ì§ì ‘ ì…ë ¥í•´ë³´ì„¸ìš”',
        value = ['ì‹ë¬¼', 'í™”ë¶„'],
        suggestions = ['ì‹ë¬¼', 'í™”ë¶„'],
        key = '1', help="í•„ìš”í•˜ì§€ ì•Šì€ ë‹¨ì–´ë¥¼ ì§ì ‘ ì„¤ì •í•˜ì—¬ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

##ì›Œë“œ í´ë¼ìš°ë“œ##
def get_tfidf_top_words(df, keyword_no):
    tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords)
    tfidf = tfidf_vectorizer.fit_transform(df['ì œëª©+ë‚´ìš©(nng)'].values)
    tfidf_df = pd.DataFrame(tfidf.todense(), columns=tfidf_vectorizer.get_feature_names_out())
    tfidf_top_words = tfidf_df.sum().sort_values(ascending=False).head(keyword_no).to_dict()
    tfidf_top_words = dict(tfidf_top_words)
    return tfidf_top_words

def get_count_top_words(df, keyword_no):
    count_vectorizer = CountVectorizer(stop_words=stopwords)
    count = count_vectorizer.fit_transform(df['ì œëª©+ë‚´ìš©(nng)'].values)
    count_df = pd.DataFrame(count.todense(), columns=count_vectorizer.get_feature_names_out())
    count_top_words = count_df.sum().sort_values(ascending=False).head(keyword_no).to_dict()
    return count_top_words

try :
    if type == 'ë‹¨ìˆœ ë¹ˆë„(Countvecterize)' :
        words = get_count_top_words(standard_df, keyword_no)
    else :
        words = get_tfidf_top_words(standard_df, keyword_no)

    #ì›Œë“œí´ë¼ìš°ë“œ
    wc = WordCloud(background_color="white", colormap='Spectral', contour_color='steelblue', font_path="/app/streamlit/font/Pretendard-Bold.otf")
    wc.generate_from_frequencies(words)

    ## ë™ì  ì›Œë“œ í´ë¼ìš°ë“œ ##
    # ì»¬ëŸ¬ íŒ”ë ˆíŠ¸ ìƒì„±
    word_list = []
    freq_list = []
    fontsize_list = []
    position_list = []
    orientation_list = []
    color_list = []

    for (word, freq), fontsize, position, orientation, color in wc.layout_:
        word_list.append(word)
        freq_list.append(freq)
        fontsize_list.append(fontsize)
        position_list.append(position)
        orientation_list.append(orientation)
        color_list.append(color)

    # get the positions
    x = []
    y = []
    for i in position_list:
        x.append(i[0])
        y.append(i[1])

    # WordCloud ì‹œê°í™”ë¥¼ ìœ„í•œ Scatter Plot ìƒì„±
    hover_text = word_list  # í‚¤ì›Œë“œë§Œ í¬í•¨í•œ í…ìŠ¤íŠ¸ ìƒì„±

    # ìˆ«ìê°’ì„ ì›í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ê¸° ìœ„í•œ hovertemplate ì„¤ì •
    hover_template = "<b>%{text}</b><br>Count: %{customdata[0]}"

    fig = go.Figure(go.Scatter(
        x=x, y=y, mode="text",
        text=hover_text,
        customdata=list(zip(freq_list)),  # ìˆ«ìê°’ì„ customdataë¡œ ì „ë‹¬
        hovertemplate=hover_template,  # hovertemplate ì„¤ì •
        textfont=dict(size=fontsize_list, color=color_list),
    ))

    fig.update_layout(
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        hovermode='closest'
    )

    st.plotly_chart(fig, use_container_width=True)

except :
    st.warning('ì˜í–¥ë„ ë²”ìœ„ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”! ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤')    

#########Section2 - í‚¤ì›Œë“œíë ˆì´íŒ…############
st.markdown("<h2 id='section2'>ì„œë¸Œíƒ€ì´í‹€ 2 ë‚´ìš©</h2>", unsafe_allow_html=True)
st.write("ì—¬ê¸°ì— ì„œë¸Œíƒ€ì´í‹€ 2ì˜ ë‚´ìš©ì„ ì‘ì„±í•©ë‹ˆë‹¤.")

#########Section3 - í‚¤ì›Œë“œ deepdive(ì‹œê³„ì—´)############
st.markdown("<h2 id='section3'>ì„œë¸Œíƒ€ì´í‹€ 3 ë‚´ìš©</h2>", unsafe_allow_html=True)
st.write("ì—¬ê¸°ì— ì„œë¸Œíƒ€ì´í‹€ 3ì˜ ë‚´ìš©ì„ ì‘ì„±í•©ë‹ˆë‹¤.")

#########Section4 - í‚¤ì›Œë“œ deepdive(ë„¤íŠ¸ì›Œí¬ ë¶„ì„)############
st.markdown("<h2 id='section4'>ì„œë¸Œíƒ€ì´í‹€ 4 ë‚´ìš©</h2>", unsafe_allow_html=True)
st.write("ì—¬ê¸°ì— ì„œë¸Œíƒ€ì´í‹€ 4ì˜ ë‚´ìš©ì„ ì‘ì„±í•©ë‹ˆë‹¤.")